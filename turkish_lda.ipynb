{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from TurkishStemmer import TurkishStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/busraalbayrak/Desktop/MY498-Capstone-Project/scripts/turkish_lda.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/busraalbayrak/Desktop/MY498-Capstone-Project/scripts/turkish_lda.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Load data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/busraalbayrak/Desktop/MY498-Capstone-Project/scripts/turkish_lda.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../data/pre-processed_tr.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/busraalbayrak/Desktop/MY498-Capstone-Project/scripts/turkish_lda.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m minutes_tr \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(file_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/busraalbayrak/Desktop/MY498-Capstone-Project/scripts/turkish_lda.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(minutes_tr))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1779\u001b[0m         nrows\n\u001b[1;32m   1780\u001b[0m     )\n\u001b[1;32m   1781\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 230\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    231\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:1037\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:1083\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:1158\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/common.py:1433\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[39m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m     \u001b[39m#  here too.\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m     \u001b[39m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m     \u001b[39m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m   1429\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[1;32m   1430\u001b[0m     )\n\u001b[0;32m-> 1433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   1434\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1435\u001b[0m \u001b[39m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1436\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m   1477\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(arr_or_dtype, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load stopwords\n",
    "stopwords_file = '../data/stopwords-tr.txt'\n",
    "with open(stopwords_file, 'r', encoding='utf-8') as f:\n",
    "    stopwords_list = [line.strip() for line in f]\n",
    "\n",
    "# Load proper nouns\n",
    "proper_nouns_file = '../data/isimler.txt'\n",
    "with open(proper_nouns_file, 'r', encoding='utf-8') as f:\n",
    "    proper_nouns = [line.strip().lower() for line in f]\n",
    "    # Extend stopwords with proper nouns\n",
    "stopwords_list.extend(proper_nouns)\n",
    "\n",
    "# Load data\n",
    "file_path = '../data/pre-processed_tr.csv'\n",
    "minutes_tr = pd.read_csv(file_path)\n",
    "print(len(minutes_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154116\n"
     ]
    }
   ],
   "source": [
    "# Remove speeches with word count less than 50\n",
    "minutes_tr = minutes_tr[minutes_tr['speech'].apply(lambda x: len(x.split()) >= 50)]\n",
    "print(len(minutes_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_to_remove = [\n",
    "    \"Çok teşekkür ederim Sayın Başkanım\",\n",
    "    \"Teşekkür ederim Sayın Başkanım\",\n",
    "    \"Çok teşekkür ederim Sayın Başkan\",\n",
    "    \"Sayın Başkan, teşekkür ederim\",\n",
    "    \"Teşekkür ediyoruz\",\n",
    "    \"Teşekkür ediyorum Sayın Başkan\",\n",
    "    \"Teşekkür ediyorum\",\n",
    "    \"Çok teşekkür ederim\",\n",
    "    \"Teşekkürler Başkan\",\n",
    "    \"Teşekkür ederim\",\n",
    "    \"Teşekkürler\",\n",
    "    \"Teşekkür ediyorum\",\n",
    "    \"Buyrun\",\n",
    "    \"Sayın milletvekilleri\",\n",
    "    \"Kabul edilmiştir\",\n",
    "    \"Sayın Başkan\",\n",
    "    \"Değerli arkadaşlar\",\n",
    "    \"…\",\n",
    "    \"Oylama işlemi tamamlanmıştır\"\n",
    "]\n",
    "\n",
    "# Create a single regular expression pattern to match all phrases\n",
    "pattern = re.compile(\"|\".join([re.escape(phrase) for phrase in phrases_to_remove]), re.IGNORECASE)\n",
    "\n",
    "# Function to remove specified phrases using regex\n",
    "def remove_phrases(text, pattern):\n",
    "    return pattern.sub(\"\", text)\n",
    "\n",
    "minutes_tr['speech'] = minutes_tr['speech'].apply(lambda x: remove_phrases(str(x), pattern))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the stemmer\n",
    "stemmer = TurkishStemmer()\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text, stopwords_list, stemmer):\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and stem tokens\n",
    "    tokens = [stemmer.stem(token.lower()) for token in tokens if token.lower() not in stopwords_list]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all speeches\n",
    "minutes_tr['tokens'] = minutes_tr['speech'].apply(lambda x: preprocess_text(x, stopwords_list, stemmer))\n",
    "\n",
    "# Flatten the list of tokens to count document frequencies\n",
    "all_tokens = [token for sublist in minutes_tr['tokens'] for token in sublist]\n",
    "token_counts = Counter(all_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove meaningles tokens after stemming and procedural tokens\n",
    "tokens_to_exclude = [\"türki\", \"alkış\", \"ünç\", \"meç\", \"mi\", \"mı\", \"det\", \"inç\", \"birinç\", \"da\", \"do\", \"eden\", \"etmeyen\", \"etmek\",\n",
    "                     \"unç\", \"nci\", \"kabul\", \"arkadaş\", \"istiyor\", \"ail\", \"devl\", \"şit\", \"kes\", \"kadar\", \"söz\", \"or\", \"mus\", \"karş\",\n",
    "                     \"diyor\", \"söylüyor\", \"çiftç\", \"ülk\", \"den\", \"dan\", \"da\", \"d\", \"e\" ,\"te\", \"ü\", \"gı\", \"tar\", \"mers\", \"de\", \"tasar\",\n",
    "                     \"sür\", \"buyur\", \"ediyor\", \"eder\", \"sayı\", \"fıkra\", \"yıl\", \" etmek\", \"mecl\", \"maalesef\", \"an\", \"hep\", \"halk\",\n",
    "                     \"lazım\", \"bak\", \"dur\", \"sor\", \"ar\", \"ım\", \"siz\", \"baka\", \"şimt\", \"seç\", \"say\", \"kanu\", \"hakk\", \"hükm\"]\n",
    "# Filter tokens with document frequency below 10\n",
    "min_doc_freq = 10\n",
    "tokens_to_keep = {token for token, count in token_counts.items() if count >= min_doc_freq and token not in tokens_to_exclude}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter tokens in each speech\n",
    "minutes_tr['tokens'] = minutes_tr['tokens'].apply(lambda tokens: [token for token in tokens if token in tokens_to_keep])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['büyük', 'millet', 'birleşim', 'açıyor', 'çoğunluk', 'var', 'günde', 'geçiyor', 'anayasa', 'milletvekil', 'görev', 'başlama', 'ant', 'içme', 'gerekmek', 'geçen', 'birleş', 'ant', 'iç', 'nden', 'birleş', 'ant', 'içmek', 'isteyen', 'kürsü', 'davet', 'büyük', 'millet', 'başkanlık', 'cumhuri', 'anayasa', 'madde', 'uyar', 'bakan', 'kuru', 'istifa', 'yen', 'hükümet', 'kurulunca', 'bakan', 'kuru', 'görev', 'devam', 'istendik', 'bilgi', 'sunar', 'bilgi', 'sunul', 'cumhurbaşkanlık', 'bakan', 'kuru', 'kurulma', 'görevlendirme', 'ilişk', 'tezkere', 'var', 'okutuyor', 'büyük', 'millet', 'başkanlık', 'bakan', 'kuru', 'kurulma', 'cumhuri', 'anayasa', 'madde', 'uyar', 'i̇stanbul', 'milletveki', 'adalet', 'kalkın', 'parti', 'genel', 'başkan', 'tayyip', 'erdoğan', 'görevlendiril', 'seçilecek', 'bakan', 'atanma', 'yapıldık', 'bakan', 'kuru', 'liste', 'gönderilecek', 'bilgi', 'sunar', 'günde', 'kısm', 'geçiyor', 'gündem', 'büyük', 'millet', 'başkan', 'seçim', 'yapacak', 'başkanlık', 'aday', 'göster', 'önerge', 'var', 'müracaat', 'sıra', 'okutuyor', 'büyük', 'millet', 'başkanlık', 'anayasa', 'i̇çtüzüğün', 'madde', 'uyar', 'döne', 'devr', 'tbmm', 'başkan', 'aday', 'ankar', 'milletveki', 'cemil', 'çiçek', 'adaylık', 'arz', 'teklif', 'olunur', 'anayasa', 'i̇çtüzüğün', 'madde', 'uyar', 'döne', 'devr', 'tbmm', 'başkan', 'aday', 'ankar', 'milletveki', 'cemil', 'çiçek', 'adaylık', 'arz', 'teklif', 'büyük', 'millet', 'başkanlık', 'anayasa', 'i̇çtüzüğün', 'madde', 'uyar', 'döne', 'devr', 'tbmm', 'başkanlık', 'aday', 'gerek', 'saygı', 'arz', 'büyük', 'millet', 'başkanlık', 'döne', 'büyük', 'millet', 'başkanlık', 'milliyetç', 'hareket', 'parti', 'antalya', 'milletveki', 'prof', 'dr', 'tunç', 'aday', 'gösteriyor', 'gerek', 'arz', 'saygı', 'anayasa', 'i̇çtüzüğün', 'madde', 'uyar', 'döne', 'devr', 'tbmm', 'başkanlık', 'aday', 'gerek', 'saygı', 'arz', 'meclis', 'başkanlık', 'isim', 'alfabe', 'sıra', 'mühür', 'oy', 'pusula', 'yer', 'alan', 'aday', 'adlar', 'okuyor', 'cemil', 'çiçek', 'ankar', 'milletveki', 'ankar', 'milletveki', 'tunç', 'toskay', 'antalya', 'milletveki', 'anayasa', 'madde', 'dördünç', 'uyar', 'başkan', 'gizl', 'oyl', 'yapılacak', 'başkan', 'seçilebilmek', 'oylama', 'üç', 'çoğunluk', 'oy', 'üçünç', 'oylama', 'salt', 'çoğunluk', 'oy', 'aranacak', 'üçünç', 'oylama', 'salt', 'çoğunluk', 'sağlanamaz', 'oylama', 'oy', 'alan', 'aday', 'dördünç', 'oyla', 'yapılacak', 'dördünç', 'oylama', 'fazl', 'oy', 'alan', 'aday', 'başkan', 'seçil', 'olacak', 'gizl', 'oylama', 'şekil', 'yapılacak', 'arz', 'komisyon', 'hükûmet', 'sıra', 'yer', 'alan', 'kâtip', 'üye', 'komisyon', 'sıra', 'kâtip', 'üye', 'adana', 'başlayarak', 'i̇stanbula', 'i̇stanbul', 'dâhil', 'hükûmet', 'sıra', 'kâtip', 'üye', 'i̇zmirden', 'başlayarak', 'zonguldak', 'zonguldak', 'dâhil', 'ad', 'okunan', 'milletvekil', 'mühür', 'birleşik', 'oy', 'pusula', 'zarf', 'verecek', 'milletveki', 'adın', 'defter', 'işaretleyecek', 'oyun', 'kullanacak', 'milletveki', 'mühür', 'birleşik', 'oy', 'pusula', 'zarf', 'aldık', 'oy', 'kabin', 'girecek', 'oy', 'pusula', 'ad', 'yazı', 'aday', 'hangi', 'oy', 'verecek', 'aday', 'adın', 'önün', 'kutucuk', 'çarp', 'işaret', 'işaretleyip', 'oy', 'pusula', 'kabin', 'zarf', 'koyduk', 'başkanlık', 'divan', 'kürsü', 'önün', 'konulan', 'oy', 'kutu', 'atacak', 'üye', 'oylama', 'dikkat', 'edecek', 'husus', 'arz', 'oy', 'kullanılırken', 'aday', 'biri', 'adın', 'önün', 'kutucuk', 'işaretlenecek', 'fazl', 'aday', 'işaretlendik', 'oy', 'pusula', 'geçers', 'sayılacak', 'kabin', 'aynı', 'renk', 'tükenmez', 'kalem', 'konul', 'üye', 'kalem', 'kullanacak', 'oy', 'pusula', 'oyun', 'belirleyecek', 'işaret', 'imza', 'karala', 'kabin', 'kalem', 'başka', 'renk', 'kalem', 'kullan', 'durum', 'oy', 'geçers', 'sayılacak', 'geçer', 'oy', 'tercih', 'belir', 'çarp', 'işare', 'dış', 'işaret', 'taşımayacak', 'kâtip', 'üye', 'yer', 'alma', 'rica', 'oylama', 'kullanılacak', 'mühür', 'oy', 'pusula', 'zarf', 'kâtip', 'üye', 'tesl', 'edil', 'oylama', 'dök', 'ad', 'çekm', 'suret', 'kişilik', 'tasnif', 'komisyon', 'tespit', 'hamarat', 'ort', 'ayt', 'sadi', 'bilgiç', 'ispar', 'selamok', 'ankar', 'balıkesir', 'seyit', 'sertçelik', 'ankar', 'tasnif', 'komisyon', 'seçilen', 'üye', 'oyla', 'işle', 'bittik', 'komisyon', 'sıra', 'yer', 'alacak', 'kâtip', 'üye', 'ant', 'içen', 'nin', 'adlar', 'okuyacak', 'oylama', 'adana', 'ilin', 'başlıyor']\n",
      "['efen', 'ism', 'okun', 'milletveki', 'milletveki', 'seçim', 'haziran', 'tunce', 'i̇l', 'kurul', 'mazbata', 'almak', 'kazan', 'sahip', 'olduk', 'hak', 'anayasa', 'i̇ç', 'tüzük', 'belirtil', 'anayasa', 'madde', 'der', 'milletveki', 'milletveki', 'görev', 'başlarken', 'aşağı', 'yem', 'içer', 'anayasa', 'madde', 'i̇sterseniz', 'kürsü', 'izah', 'edey']\n",
      "['anayasa', 'madde', 'büyük', 'millet', 'i̇ç', 'tüzük', 'hüküm', 'yöne', 'i̇ç', 'tüzük', 'madde', 'milletvekil', 'katıldık', 'birleş', 'yem', 'birleş', 'yem', 'etmez', 'ikinç', 'birleş', 'katılır', 'yem', 'geçen', 'birleş', 'var', 'yem', 'etme', 'yem', 'etmeme', 'neden', 'bugü', 'tane', 'milletvekil', 'halkoy', 'seçilip', 'bura', 'gelme']\n",
      "['kupa', 'kaldırıl', 'tasnif', 'komisyon', 'üye', 'yer', 'als', 'tasnif', 'komisyon', 'üye', 'isim', 'okuyor', 'sadi', 'bilgiç', 'seyit', 'sertçelik', 'hamarat', 'büyük', 'millet', 'başkanlık', 'büyük', 'millet', 'başkan', 'tur', 'oylama', 'katıl', 'kullanılan', 'oylar', 'dağıl', 'aşağı', 'gösteril', 'sayg', 'arz', 'olunur', 'ankar', 'milletveki', 'cemil', 'çiçek', 'antalya', 'milletveki', 'tunç', 'toskay', 'ankar', 'milletveki', 'ankar', 'milletveki', 'büyük', 'millet', 'başkan', 'adaylık', 'çekildik', 'tezker', 'sun', 'okutuyor', 'büyük', 'millet', 'başkanlık', 'döne', 'devr', 'büyük', 'millet', 'başkan', 'adaylık', 'feragat', 'gerek', 'arz']\n",
      "['büyük', 'millet', 'birleşim', 'i̇kinci', 'oturum', 'açıyor', 'ikinç', 'oylama', 'başlıyor', 'oylama', 'üç', 'çoğunluk', 'oy', 'aranacak', 'oylama', 'dök', 'ad', 'çekm', 'suret', 'kişilik', 'tasnif', 'komisyon', 'tespit', 'haç', 'türkok', 'hatay', 'haç', 'türkok', 'akyürek', 'şanlıurf', 'efen', 'akyürek', 'kayatürk', 'van', 'kayatürk', 'van', 'hamzaoğul', 'diyarbakır', 'hamzaoğul', 'galip', 'ensariok', 'diyarbakır', 'ensariok', 'korkmaz', 'ispar', 'özel', 'ispar', 'özel', 'semiha', 'ayt', 'fevai', 'arslan', 'düzç', 'efen', 'van', 'ism', 'çekmiş', 'gel', 'tama', 'kişilik', 'tasnif', 'komisyon', 'üye', 'tasnif', 'komisyon', 'üye', 'isim', 'tekrar', 'okuyor', 'efen', 'van', 'semiha', 'ayt', 'özel', 'ispar', 'korkmaz', 'ispar', 'haç', 'türkok', 'hatay', 'tasnif', 'komisyon', 'seçilen', 'üye', 'oyla', 'işle', 'bittik', 'komisyon', 'sıra', 'yer', 'alacak', 'ikinç', 'oylama', 'kullanılacak', 'zarf', 'mühür', 'pusula', 'kâtip', 'üye', 'tesl', 'edel', 'oylama', 'adana', 'ilin', 'başlayacak']\n"
     ]
    }
   ],
   "source": [
    "lda_input = minutes_tr['tokens'].tolist()\n",
    "\n",
    "# Example output: print the first 5 token lists to check\n",
    "for tokens in lda_input[5:10]:\n",
    "    print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/busraalbayrak/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(tokenizer=lambda x: x, preprocessor=lambda x: x, lowercase=False)\n",
    "X = vectorizer.fit_transform(lda_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "n_topics = 20 \n",
    "lda = LatentDirichletAllocation(n_components=n_topics, \n",
    "                                learning_method='online', \n",
    "                                max_iter=10, \n",
    "                                random_state=0,\n",
    "                                batch_size=1024,\n",
    "                                n_jobs=1 \n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "lda.fit(X)\n",
    "\n",
    "# Display the top words for each topic\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "yol proje ihale araç ak firma demir şehir trafik devam hav tren liman ulaştır hizmet i̇stanbul köprü havaliman hızl yap\n",
      "Topic 1:\n",
      "yüz ülke ekonomi oran gelir türkiye verg değer dünya sektör banka ekonomik son dış önem yatır yük şirket üzer vergi\n",
      "Topic 2:\n",
      "yöne merkezî bütçe hesap bütç genel kur ödenek bakanlık başkanlık müdürlük topla hizmet gelir kamu üniversite a gider b türk\n",
      "Topic 3:\n",
      "işçi çalışan işç dil hak çalış sendika taşeron sözleşme topl emek iş emekçi ücret yasa işveren kamu kül kadro hakk\n",
      "Topic 4:\n",
      "sağlık çocuk kat hastane engel sosyal kadın yaş çalışan gün hizmet şiddet insan aile hak vatandaş hastalık yüz ev bakanlık\n",
      "Topic 5:\n",
      "say bakan konu zaman ifade biliyor başka tane gerçek bura başkan parti söyl grup cevap yap konuşma yapıyor meclis şekil\n",
      "Topic 6:\n",
      "madde kanu kanun teklif değişiklik düzenle yasa düzenleme kamu komisyon hakk görev tarih şekil hükm tasarı ilişk kararname anayasa süre\n",
      "Topic 7:\n",
      "lira fiyat borç esnaf vatandaş çiftçi yüz destek ürün emek para üret zam üretici asgari kret ücret elektrik par maaş\n",
      "Topic 8:\n",
      "orman alan su yer maden insan depre vatandaş köy çevr bölge üzer bina arazi ev alt enerj gün doğal nükleer\n",
      "Topic 9:\n",
      "madde say önerge milletveki millet teklif büyük başkanlık önerg kanu arz oylar grup sır görüşülmek sunuyor katılıyor komisyon var ibare\n",
      "Topic 10:\n",
      "karar hukuk mahkeme yarg hak ceza suç cezaev adalet hakk dava görev ana yasa mahkem yargı özgürlük i̇nsan avukat insan\n",
      "Topic 11:\n",
      "millet şehit diliyor rahmet türk değer allah gün sayg büyük milletvekil gazi selamlıyor bugü atatürk tarih hayat millî baş dünya\n",
      "Topic 12:\n",
      "parti milletvekil değer ifade iktidar ülke millet siyasi orta türkiye büyük demokrasi karş süreç bugü etmek topl zaman meclis üzer\n",
      "Topic 13:\n",
      "eğit öğretmen üniversite okul genç öğrenci meslek millî üniversi öğrenç sınav kadro görev bakanlık yurt çocuk öğre vakıf bil personel\n",
      "Topic 14:\n",
      "bölge belediye il ilçe turizm köy spor su bakanlık alan merkez beledi büyükşehir proje yer say bakan baraj iller büyük\n",
      "Topic 15:\n",
      "konu alan önem gerek ülke amaç çalışma genel büyük bilgi yer bakanlık meclis sorun faaliyet alınma araştırma çalış yönelik kaynak\n",
      "Topic 16:\n",
      "insan ülke gün iktidar kürt bugü karş çocuk yer akp sıra iç katliam biliyor diyen darbe fetö tarih dünya saray\n",
      "Topic 17:\n",
      "komisyon kanu madde görüşme yer teklif rapor tüzük i̇ç sıra oylar üzer oylama alan sunuyor karar tasarı tasar sır uygun\n",
      "Topic 18:\n",
      "ülke türkiye terör türk politika suriye dünya dış birlik güvenlik silah bölge uluslarara devlet örgüt avrup sınır iç millet güç\n",
      "Topic 19:\n",
      "başkan parti genel seç say grup meclis oy kuru cumhurbaşkan bas kurul başkanlık gün ak milletveki parti̇ beledi seçim veki\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 20\n",
    "display_topics(lda, vectorizer.get_feature_names_out(), no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
